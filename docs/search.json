[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Last updated 04/05/2025"
  },
  {
    "objectID": "code/code_test.html",
    "href": "code/code_test.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "import hashlib\n\npw = 'bigbear'\nhpw = hashlib.sha256(pw.encode()).hexdigest()\nprint(hpw)\n\nf98f3d8cbcfa62aac83f1abb6411e40c5da9b2cf9ed67c0227b8675351a04500"
  },
  {
    "objectID": "projects/MGTA495/hw1_questions.html",
    "href": "projects/MGTA495/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/hw1_questions.html#introduction",
    "href": "projects/MGTA495/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/hw1_questions.html#data",
    "href": "projects/MGTA495/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_stata('karlan_list_2007.dta')\ndisplay(df.head())\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. For at least one variable, perform the test as both t-test (use the formula in the class slides) and separately as a linear regression (regress for example mrm2 on treatment); confirm both methods yield the exact same results. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "projects/MGTA495/hw1_questions.html#experimental-results",
    "href": "projects/MGTA495/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made (you can do this as a bivariate linear regression if you want). It may help to confirm your calculations match Table 2a Panel A. Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or something that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions…\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plots: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/MGTA495/hw1_questions.html#simulation-experiment",
    "href": "projects/MGTA495/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms at sample sizes 50, 200, 500, and 1000. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. The repeat for the other 3 histograms. Explain this sequence of histograms and its relationship to the central limit theorem to the reader."
  },
  {
    "objectID": "projects/school/hw3.html",
    "href": "projects/school/hw3.html",
    "title": "Example 2",
    "section": "",
    "text": "##Example 2\nExample histogram below:\nThis is a protected section. Here’s a Python-generated histogram:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(100)\nplt.hist(x)\nplt.show()"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Logos used on this site are the property of their respective owners. No endorsement or affiliation is implied. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1\n\n\n\nApr 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\n\nApr 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSan Diego Real Estate Shiny App\n\n\n\nNov 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample Power BI Report\n\n\n\nJun 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "bonus.html",
    "href": "bonus.html",
    "title": "Rex",
    "section": "",
    "text": "🦖🌵\n\n\nScore: 0\n\n\n\n Jump!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "Wesley is a data-driven operations analyst and Marine Corps veteran with a proven record of turning complex data into actionable insights. With experience spanning financial analytics, business intelligence, and process optimization, he brings precision and purpose to every challenge. Outside of work, he enjoys gardening, woodworking, and exploring San Diego’s hiking trails.\n\n\nUniversity of California, San Diego - Rady School of Management | M.S. in Business Analytics | 2024 - Present\nArizona State University - W.P. Carey School of Business | B.S. in Economics | 2018 - 2023\n\n\n\nAcademy Securities | Operations Analyst | 2023 - Present\nUnited States Marine Corps | Chief Force Deployment Analyst | 2015 - 2023"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "University of California, San Diego - Rady School of Management | M.S. in Business Analytics | 2024 - Present\nArizona State University - W.P. Carey School of Business | B.S. in Economics | 2018 - 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "Academy Securities | Operations Analyst | 2023 - Present\nUnited States Marine Corps | Chief Force Deployment Analyst | 2015 - 2023"
  },
  {
    "objectID": "projects/work/shiny_real_estate.html",
    "href": "projects/work/shiny_real_estate.html",
    "title": "San Diego Real Estate Shiny App",
    "section": "",
    "text": "Here is where I will enter my project notes.\n\nClick here to open the app in a new tab."
  },
  {
    "objectID": "projects/work/shiny_real_estate.html#project-notes",
    "href": "projects/work/shiny_real_estate.html#project-notes",
    "title": "San Diego Real Estate Shiny App",
    "section": "",
    "text": "Here is where I will enter my project notes.\n\nClick here to open the app in a new tab."
  },
  {
    "objectID": "projects/school/hw1.html",
    "href": "projects/school/hw1.html",
    "title": "Example 1",
    "section": "",
    "text": "Example dataframe below:\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"A\": [1, 2, 3],\n    \"B\": [4, 5, 6]\n})\n\nprint(df)\n\n   A  B\n0  1  4\n1  2  5\n2  3  6"
  },
  {
    "objectID": "projects/MGTA495/hw1_nb.html",
    "href": "projects/MGTA495/hw1_nb.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport pyrsm as rsm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\ntest_variables = ['hpa', 'freq', 'female', 'redcty', 'bluecty']\n\nfor var in test_variables:\n    control = df.loc[df.treatment == 0, var].dropna()\n    treatment = df.loc[df.treatment == 1, var].dropna()\n\n    t_stat, pval = ttest_ind(control, treatment)\n    print(f'''\n    t-statistic: {t_stat}\n    p-value: {pval}\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the mean {var} \n    of the two samples are equal.''')\n\n    m = rsm.model.regress(data=df,\n                      rvar=var,\n                      evar=['treatment'],\n    )\n    print(f'Linear regression results for {var}:')\n    print(m.summary(main=False))\n\n\n    t-statistic: -0.944145044786662\n    p-value: 0.34510008823759086\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean hpa \n    of the two samples are equal.\nLinear regression results for hpa:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.891 df(1, 50081), p.value 0.345\nNr obs: 50,083\nNone\n\n    t-statistic: 0.11089297035979982\n    p-value: 0.9117016644344591\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean freq \n    of the two samples are equal.\nLinear regression results for freq:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\nNone\n\n    t-statistic: 1.7583691871450704\n    p-value: 0.07869095826986476\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean female \n    of the two samples are equal.\nLinear regression results for female:\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972\nNone\n\n    t-statistic: -0.9041867297482356\n    p-value: 0.3659007540247129\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean redcty \n    of the two samples are equal.\nLinear regression results for redcty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.818 df(1, 49976), p.value 0.366\nNr obs: 49,978\nNone\n\n    t-statistic: 0.8535382534940722\n    p-value: 0.3933649744168656\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean bluecty \n    of the two samples are equal.\nLinear regression results for bluecty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978\nNone\n\n\nThe results of the t-test and linear regression analysis on these explanatory variables affirm that that treatment and control groups are not statistically significantly different, at the 95% confidence level.\n\ngave_df = df.groupby('treatment')['gave'].mean()\ngave_df.index = gave_df.index.map({0: 'Control', 1: 'Treatment'})\n\nplt.bar(gave_df.index, gave_df.values)\nplt.title('Proportion Who Donated by Group')\nplt.xlabel('Group')\nplt.ylabel('Proportion Who Donated')\ndisplay(gave_df)\nplt.show()\n\ntreatment\nControl      0.017858\nTreatment    0.022039\nName: gave, dtype: float64\n\n\n\n\n\n\n\n\n\n\ncontrol = df.loc[df.treatment == 0, 'gave'].dropna()\ntreatment = df.loc[df.treatment == 1, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the response rate of the two samples are equal.''')\n\n\nt-statistic: -3.101361000543946\np-value: 0.0019274025949016982\n\nAt the 95% confidence level, we reject the null hypothesis \nthat the response rate of the two samples are equal.\n\n\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        17:53:15   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nGiven the low p-value from both the t-test and probit regression, we can conclude that people are more likely to respond to a request for charitable donations when informed that their donations will be met with a matching donation.\n\ndf['ratio'] = df['ratio'].astype(str)\ndf['ratio'] = pd.Categorical(df['ratio'], categories=['Control', '1', '2', '3'], ordered=True)\n\n\nratio_df = df.groupby('ratio')['gave'].mean()\ndisplay(ratio_df)\n\n/tmp/ipykernel_9566/157019139.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ratio_df = df.groupby('ratio')['gave'].mean()\n\n\nratio\nControl    0.017858\n1          0.020749\n2          0.022633\n3          0.022733\nName: gave, dtype: float64\n\n\n\ng1 = '1'\ng2 = '2'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 1:1 - 0.020749124225276205\n    Response rate for 2:1 - 0.0226333752469912\n    t-statistic: -0.96504713432247\n    p-value: 0.33453168549723933\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 1:1 and 2:1 are equal.\n\n\n\ng1 = '2'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 2:1 - 0.0226333752469912\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -0.05011583793874515\n    p-value: 0.9600305283739325\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 2:1 and 3:1 are equal.\n\n\n\ng1 = '1'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 1:1 - 0.020749124225276205\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -1.0150255853798622\n    p-value: 0.3101046637086672\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 1:1 and 3:1 are equal.\n\n\n\nprobit_model2 = smf.probit('gave ~ ratio', data=df).fit()\nprint(probit_model2.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        17:53:16   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio[T.1]     0.0616      0.036      1.726      0.084      -0.008       0.132\nratio[T.2]     0.0980      0.035      2.792      0.005       0.029       0.167\nratio[T.3]     0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\n\n\n\ntreatment_df = df.loc[df.treatment == 1].copy()\ntreatment_df = treatment_df[['gave', 'ratio']].dropna()\ntreatment_df['ratio'] = pd.Categorical(\n    treatment_df['ratio'], \n    categories=['1', '2', '3'], \n    ordered=True\n)\nprint(treatment_df.groupby('ratio', observed=True)['gave'].mean())\n\nprobit_model3 = smf.probit('gave ~ ratio', data=treatment_df).fit()\nprint(probit_model3.summary())\n\nratio\n1    0.020749\n2    0.022633\n3    0.022733\nName: gave, dtype: float64\nOptimization terminated successfully.\n         Current function value: 0.105851\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                33396\nModel:                         Probit   Df Residuals:                    33393\nMethod:                           MLE   Df Model:                            2\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0001844\nTime:                        17:53:16   Log-Likelihood:                -3535.0\nconverged:                       True   LL-Null:                       -3535.6\nCovariance Type:            nonrobust   LLR p-value:                    0.5211\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.0385      0.027    -75.373      0.000      -2.092      -1.986\nratio[T.2]     0.0363      0.038      0.965      0.335      -0.037       0.110\nratio[T.3]     0.0382      0.038      1.015      0.310      -0.036       0.112\n==============================================================================\n\n\n\nprint(f'Difference between 3:1 response rate and 2:1 response rate: {ratio_df['3'] - ratio_df['2']}')\nprint(f'Difference between 2:1 response rate and 1:1 response rate: {ratio_df['2'] - ratio_df['1']}')\n\nDifference between 3:1 response rate and 2:1 response rate: 0.00010002398025293902\nDifference between 2:1 response rate and 1:1 response rate: 0.0018842510217149944\n\n\n\ncoefs = probit_model2.params\n\n# Coefficients: interpreted as difference from 'Control'\ncoef_1 = coefs['ratio[T.1]']\ncoef_2 = coefs['ratio[T.2]']\ncoef_3 = coefs['ratio[T.3]']\n\n# Compute pairwise differences between levels\ndiff_3_vs_2 = coef_3 - coef_2\ndiff_2_vs_1 = coef_2 - coef_1\n\nprint(f\"3:1 vs 2:1 difference (from regression): {diff_3_vs_2:.4f}\")\nprint(f\"2:1 vs 1:1 difference (from regression): {diff_2_vs_1:.4f}\")\n\n3:1 vs 2:1 difference (from regression): 0.0019\n2:1 vs 1:1 difference (from regression): 0.0363\n\n\n\nmfx = probit_model2.get_margeff()\nprint(mfx.summary())\n\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio[T.1]     0.0031      0.002      1.724      0.085      -0.000       0.007\nratio[T.2]     0.0049      0.002      2.786      0.005       0.001       0.008\nratio[T.3]     0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n\nmarginal_effects = mfx.margeff\nprint(\"Marginal effects by ratio level:\", marginal_effects)\n\n# Compare 2:1 to 1:1, 3:1 to 2:1\ndiff_2_vs_1 = marginal_effects[1] - marginal_effects[0]\ndiff_3_vs_2 = marginal_effects[2] - marginal_effects[1]\n\nprint(f\"Estimated increase from 1:1 to 2:1: {diff_2_vs_1:.4f}\")\nprint(f\"Estimated increase from 2:1 to 3:1: {diff_3_vs_2:.4f}\")\n\nMarginal effects by ratio level: [0.0030624  0.0048688  0.00496109]\nEstimated increase from 1:1 to 2:1: 0.0018\nEstimated increase from 2:1 to 3:1: 0.0001\n\n\n\ncontrol = df.loc[df.treatment == 0, 'amount'].dropna()\ntreatment = df.loc[df.treatment == 1, 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the donation amount of the two samples are equal.''')\n\n\nt-statistic: -1.8605020225753781\np-value: 0.06282038947470686\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the donation amount of the two samples are equal.\n\n\n\ncontrol = df.loc[(df.treatment == 0) & (df.gave == 1), 'amount'].dropna()\ntreatment = df.loc[(df.treatment == 1) & (df.gave == 1), 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the donation amount of the two samples are equal.''')\n\n\nt-statistic: 0.5808388615237938\np-value: 0.5614758782284279\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the donation amount of the two samples are equal.\n\n\n\ndonated_treatment = df.loc[(df.gave == 1) & (df.treatment == 1)].copy()\ndonated_control = df.loc[(df.gave == 1) & (df.treatment == 0)].copy()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\naxes[0].set_ylabel(\"Frequency\")\n\nfor val in [0, 1]:\n    subset = df.loc[(df.gave == 1) & (df.treatment == val)].copy()\n    axes[val].hist(subset['amount'], bins=10)\n    axes[val].axhline(y=subset['amount'].mean(), color='r', linestyle='--')\n    axes[val].set_title(f'Amount Donated for {\"Treatment\" if val == 1 else \"Control\"} Group')\n    axes[val].set_xlabel(\"Dollars Donated\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nctr_p = 0.018\ntrt_p = 0.022\n\nsim_ctr = np.random.binomial(n=1, p=ctr_p, size=10_000)\nsim_trt = np.random.binomial(n=1, p=trt_p, size=10_000)\n\nsim_diff = sim_trt - sim_ctr\nsim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n\nprint(sim_diff.mean())\nprint(sim_diff_mean)\n\n0.0012\n0.0012000000000000031\n\n\n\ncumulative_avg = np.cumsum(sim_diff) / np.arange(1, len(sim_diff) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg)\nplt.axhline(y=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference (Treatment - Control)')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom cycler import cycler\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#375a7f']) \n\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10), sharey=True, sharex=True)\naxes = axes.flatten()\naxes[0].set_ylabel(\"Frequency\")\naxes[2].set_ylabel(\"Frequency\")\n\nfor ax, size in enumerate([50, 200, 500, 1000]):\n    samples = []\n    for i in range(1000):\n        sim_ctr = np.random.binomial(n=1, p=ctr_p, size=size)\n        sim_trt = np.random.binomial(n=1, p=trt_p, size=size)\n\n        sim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n        samples.append(sim_diff_mean)\n    \n    axes[ax].hist(samples, bins=10)\n    axes[ax].axvline(x=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\n    axes[ax].legend()\n    axes[ax].set_title(f'Average Difference from {size} Draws')\n    axes[ax].set_xlabel(\"Difference in Response Rate\")\n\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "code/old_code.html",
    "href": "code/old_code.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_questions.html",
    "href": "projects/MGTA495/HW1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_questions.html#introduction",
    "href": "projects/MGTA495/HW1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_questions.html#data",
    "href": "projects/MGTA495/HW1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. For at least one variable, perform the test as both t-test (use the formula in the class slides) and separately as a linear regression (regress for example mrm2 on treatment); confirm both methods yield the exact same results. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\n\ntest_variables = ['hpa', 'freq', 'female', 'redcty', 'bluecty']\n\nfor var in test_variables:\n    control = df.loc[df.treatment == 0, var].dropna()\n    treatment = df.loc[df.treatment == 1, var].dropna()\n\n    t_stat, pval = ttest_ind(control, treatment)\n    print(f'''\nT-test results for {var}:\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the mean value from the two samples are equal.''')\n\n    m = rsm.model.regress(data=df,\n                      rvar=var,\n                      evar=['treatment'],\n    )\n    print(f'Linear regression results for {var}:')\n    print(m.summary(main=False))\n\n\nT-test results for hpa:\nt-statistic: -0.944145044786662\np-value: 0.34510008823759086\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the mean value from the two samples are equal.\nLinear regression results for hpa:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.891 df(1, 50081), p.value 0.345\nNr obs: 50,083\nNone\n\nT-test results for freq:\nt-statistic: 0.11089297035979982\np-value: 0.9117016644344591\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the mean value from the two samples are equal.\nLinear regression results for freq:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\nNone\n\nT-test results for female:\nt-statistic: 1.7583691871450704\np-value: 0.07869095826986476\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the mean value from the two samples are equal.\nLinear regression results for female:\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972\nNone\n\nT-test results for redcty:\nt-statistic: -0.9041867297482356\np-value: 0.3659007540247129\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the mean value from the two samples are equal.\nLinear regression results for redcty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.818 df(1, 49976), p.value 0.366\nNr obs: 49,978\nNone\n\nT-test results for bluecty:\nt-statistic: 0.8535382534940722\np-value: 0.3933649744168656\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the mean value from the two samples are equal.\nLinear regression results for bluecty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978\nNone"
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_questions.html#experimental-results",
    "href": "projects/MGTA495/HW1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made (you can do this as a bivariate linear regression if you want). It may help to confirm your calculations match Table 2a Panel A. Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or something that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions…\n\ngave_df = df.groupby('treatment')['gave'].mean()\ngave_df.index = gave_df.index.map({0: 'Control', 1: 'Treatment'})\n\nplt.bar(gave_df.index, gave_df.values)\nplt.title('Proportion Who Donated by Group')\nplt.xlabel('Group')\nplt.ylabel('Proportion Who Donated')\nplt.show()\n\n\ncontrol = df.loc[df.treatment == 0, 'gave'].dropna()\ntreatment = df.loc[df.treatment == 1, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test results:\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the response rate of the two samples are equal.''')\n\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nprint('Probit Regression Results:')\nprint(probit_model.summary())\n\n\n\n\n\n\n\n\n\nT-test results:\nt-statistic: -3.101361000543946\np-value: 0.0019274025949016982\n\nAt the 95% confidence level, we reject the null hypothesis that the response rate of the two samples are equal.\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\nProbit Regression Results:\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        23:11:48   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\ndf['ratio'] = df['ratio'].astype(str)\ndf['ratio'] = pd.Categorical(df['ratio'], categories=['Control', '1', '2', '3'], ordered=True)\n\nratio_df = df.groupby('ratio')['gave'].mean()\ndisplay(ratio_df)\n\nfor ratio in ['1', '2', '3']:\n    g1 = ratio\n    for alt_ratio in ['1', '2', '3']:\n        if g1 == alt_ratio:\n            continue\n        g2 = alt_ratio\n\n        group1 = df.loc[df.ratio == g1, 'gave'].dropna()\n        group2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\n        t_stat, pval = ttest_ind(group1, group2)\n        print(f'''\nResponse rate for {g1}:1 - {group1.mean()}\nResponse rate for {g2}:1 - {group2.mean()}\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\nprobit_model2 = smf.probit('gave ~ ratio', data=df).fit()\nprint(probit_model2.summary())\n\n\ntreatment_df = df.loc[df.treatment == 1].copy()\ntreatment_df = treatment_df[['gave', 'ratio']].dropna()\ntreatment_df['ratio'] = pd.Categorical(\n    treatment_df['ratio'], \n    categories=['1', '2', '3'], \n    ordered=True\n)\n\nprobit_model3 = smf.probit('gave ~ ratio', data=treatment_df).fit()\nprint(probit_model3.summary())\n\n\nprint(f'Difference between 3:1 response rate and 2:1 response rate: {ratio_df['3'] - ratio_df['2']}')\nprint(f'Difference between 2:1 response rate and 1:1 response rate: {ratio_df['2'] - ratio_df['1']}')\n\nmfx = probit_model2.get_margeff()\nmarginal_effects = mfx.margeff\ndiff_3_vs_2 = marginal_effects[2] - marginal_effects[1]\ndiff_2_vs_1 = marginal_effects[1] - marginal_effects[0]\n\n\nprint(f\"Estimated difference between 3:1 response rate and 2:1 response rate:: {diff_3_vs_2:.4f}\")\nprint(f\"Estimated difference between 2:1 response rate and 1:1 response rate: {diff_2_vs_1:.4f}\")\n\n/tmp/ipykernel_35226/2166398160.py:4: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\nratio\nControl    0.017858\n1          0.020749\n2          0.022633\n3          0.022733\nName: gave, dtype: float64\n\n\n\nResponse rate for 1:1 - 0.020749124225276205\nResponse rate for 2:1 - 0.0226333752469912\nt-statistic: -0.96504713432247\np-value: 0.33453168549723933\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 1:1 and 2:1 are equal.\n\nResponse rate for 1:1 - 0.020749124225276205\nResponse rate for 3:1 - 0.022733399227244138\nt-statistic: -1.0150255853798622\np-value: 0.3101046637086672\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 1:1 and 3:1 are equal.\n\nResponse rate for 2:1 - 0.0226333752469912\nResponse rate for 1:1 - 0.020749124225276205\nt-statistic: 0.96504713432247\np-value: 0.33453168549723933\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 2:1 and 1:1 are equal.\n\nResponse rate for 2:1 - 0.0226333752469912\nResponse rate for 3:1 - 0.022733399227244138\nt-statistic: -0.05011583793874515\np-value: 0.9600305283739325\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 2:1 and 3:1 are equal.\n\nResponse rate for 3:1 - 0.022733399227244138\nResponse rate for 1:1 - 0.020749124225276205\nt-statistic: 1.0150255853798622\np-value: 0.3101046637086672\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 3:1 and 1:1 are equal.\n\nResponse rate for 3:1 - 0.022733399227244138\nResponse rate for 2:1 - 0.0226333752469912\nt-statistic: 0.05011583793874515\np-value: 0.9600305283739325\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the response rate of ratio 3:1 and 2:1 are equal.\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        23:11:48   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio[T.1]     0.0616      0.036      1.726      0.084      -0.008       0.132\nratio[T.2]     0.0980      0.035      2.792      0.005       0.029       0.167\nratio[T.3]     0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\nOptimization terminated successfully.\n         Current function value: 0.105851\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                33396\nModel:                         Probit   Df Residuals:                    33393\nMethod:                           MLE   Df Model:                            2\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0001844\nTime:                        23:11:49   Log-Likelihood:                -3535.0\nconverged:                       True   LL-Null:                       -3535.6\nCovariance Type:            nonrobust   LLR p-value:                    0.5211\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.0385      0.027    -75.373      0.000      -2.092      -1.986\nratio[T.2]     0.0363      0.038      0.965      0.335      -0.037       0.110\nratio[T.3]     0.0382      0.038      1.015      0.310      -0.036       0.112\n==============================================================================\nDifference between 3:1 response rate and 2:1 response rate: 0.00010002398025293902\nDifference between 2:1 response rate and 1:1 response rate: 0.0018842510217149944\nEstimated difference between 3:1 response rate and 2:1 response rate:: 0.0001\nEstimated difference between 2:1 response rate and 1:1 response rate: 0.0018\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plots: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\ncontrol = df.loc[df.treatment == 0, 'amount'].dropna()\ntreatment = df.loc[df.treatment == 1, 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test results:\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the donation amount of the two samples are equal.''')\n\ncontrol = df.loc[(df.treatment == 0) & (df.gave == 1), 'amount'].dropna()\ntreatment = df.loc[(df.treatment == 1) & (df.gave == 1), 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test results:\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the donation amount of the two samples are equal.''')\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\naxes[0].set_ylabel(\"Frequency\")\n\nfor val in [0, 1]:\n    subset = df.loc[(df.gave == 1) & (df.treatment == val)].copy()\n    axes[val].hist(subset['amount'], bins=10)\n    axes[val].axhline(y=subset['amount'].mean(), color='r', linestyle='--', label='Mean')\n    axes[val].legend()\n    axes[val].set_title(f'Amount Donated for {\"Treatment\" if val == 1 else \"Control\"} Group')\n    axes[val].set_xlabel(\"Dollars Donated\")\n\nplt.tight_layout()\nplt.show()\n\n\nT-test results:\nt-statistic: -1.8605020225753781\np-value: 0.06282038947470686\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the donation amount of the two samples are equal.\n\nT-test results:\nt-statistic: 0.5808388615237938\np-value: 0.5614758782284279\n\nAt the 95% confidence level, we fail to reject the null hypothesis that the donation amount of the two samples are equal."
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_questions.html#simulation-experiment",
    "href": "projects/MGTA495/HW1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\nctr_p = 0.018\ntrt_p = 0.022\n\nnp.random.seed(12)\nsim_ctr = np.random.binomial(n=1, p=ctr_p, size=10_000)\nsim_trt = np.random.binomial(n=1, p=trt_p, size=10_000)\n\nsim_diff = sim_trt - sim_ctr\ncumulative_avg = np.cumsum(sim_diff) / np.arange(1, len(sim_diff) + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg)\nplt.axhline(y=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference (Treatment - Control)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms at sample sizes 50, 200, 500, and 1000. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. The repeat for the other 3 histograms. Explain this sequence of histograms and its relationship to the central limit theorem to the reader.\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10), sharey=True, sharex=True)\naxes = axes.flatten()\naxes[0].set_ylabel(\"Frequency\")\naxes[2].set_ylabel(\"Frequency\")\n\nfor ax, size in enumerate([50, 200, 500, 1000]):\n    samples = []\n    for i in range(1000):\n        sim_ctr = np.random.binomial(n=1, p=ctr_p, size=size)\n        sim_trt = np.random.binomial(n=1, p=trt_p, size=size)\n\n        sim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n        samples.append(sim_diff_mean)\n    \n    axes[ax].hist(samples, bins=10)\n    axes[ax].axvline(x=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\n    axes[ax].legend()\n    axes[ax].set_title(f'Average Difference from {size} Draws')\n    axes[ax].set_xlabel(\"Difference in Response Rate\")\n\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/MGTA495/HW1/hw1_nb.html",
    "href": "projects/MGTA495/HW1/hw1_nb.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport pyrsm as rsm\nimport matplotlib.pyplot as plt\nfrom cycler import cycler\n\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#375a7f']) \n\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\ntest_variables = ['hpa', 'freq', 'female', 'redcty', 'bluecty']\n\nfor var in test_variables:\n    control = df.loc[df.treatment == 0, var].dropna()\n    treatment = df.loc[df.treatment == 1, var].dropna()\n\n    t_stat, pval = ttest_ind(control, treatment)\n    print(f'''\nT-test results for {var}:\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the mean value from the two samples are equal.''')\n\n    m = rsm.model.regress(data=df,\n                      rvar=var,\n                      evar=['treatment'],\n    )\n    print(f'Linear regression results for {var}:')\n    print(m.summary(main=False))\n\n\n    t-statistic: -0.944145044786662\n    p-value: 0.34510008823759086\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean hpa \n    of the two samples are equal.\nLinear regression results for hpa:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.891 df(1, 50081), p.value 0.345\nNr obs: 50,083\nNone\n\n    t-statistic: 0.11089297035979982\n    p-value: 0.9117016644344591\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean freq \n    of the two samples are equal.\nLinear regression results for freq:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\nNone\n\n    t-statistic: 1.7583691871450704\n    p-value: 0.07869095826986476\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean female \n    of the two samples are equal.\nLinear regression results for female:\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972\nNone\n\n    t-statistic: -0.9041867297482356\n    p-value: 0.3659007540247129\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean redcty \n    of the two samples are equal.\nLinear regression results for redcty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.818 df(1, 49976), p.value 0.366\nNr obs: 49,978\nNone\n\n    t-statistic: 0.8535382534940722\n    p-value: 0.3933649744168656\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the mean bluecty \n    of the two samples are equal.\nLinear regression results for bluecty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978\nNone\n\n\nThe results of the t-test and linear regression analysis on these explanatory variables affirm that that treatment and control groups are not statistically significantly different, at the 95% confidence level.\n\ngave_df = df.groupby('treatment')['gave'].mean()\ngave_df.index = gave_df.index.map({0: 'Control', 1: 'Treatment'})\n\nplt.bar(gave_df.index, gave_df.values)\nplt.title('Proportion Who Donated by Group')\nplt.xlabel('Group')\nplt.ylabel('Proportion Who Donated')\ndisplay(gave_df)\nplt.show()\n\ntreatment\nControl      0.017858\nTreatment    0.022039\nName: gave, dtype: float64\n\n\n\n\n\n\n\n\n\n\ncontrol = df.loc[df.treatment == 0, 'gave'].dropna()\ntreatment = df.loc[df.treatment == 1, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the response rate of the two samples are equal.''')\n\n\nt-statistic: -3.101361000543946\np-value: 0.0019274025949016982\n\nAt the 95% confidence level, we reject the null hypothesis \nthat the response rate of the two samples are equal.\n\n\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        17:53:15   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nGiven the low p-value from both the t-test and probit regression, we can conclude that people are more likely to respond to a request for charitable donations when informed that their donations will be met with a matching donation.\n\ndf['ratio'] = df['ratio'].astype(str)\ndf['ratio'] = pd.Categorical(df['ratio'], categories=['Control', '1', '2', '3'], ordered=True)\n\n\nratio_df = df.groupby('ratio')['gave'].mean()\ndisplay(ratio_df)\n\n/tmp/ipykernel_9566/157019139.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ratio_df = df.groupby('ratio')['gave'].mean()\n\n\nratio\nControl    0.017858\n1          0.020749\n2          0.022633\n3          0.022733\nName: gave, dtype: float64\n\n\n\nfor ratio in ['1', '2', '3']:\n    g1 = ratio\n    for alt_ratio in ['1', '2', '3']:\n        if g1 == alt_ratio:\n            continue\n        g2 = alt_ratio\n\n        group1 = df.loc[df.ratio == g1, 'gave'].dropna()\n        group2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\n        t_stat, pval = ttest_ind(group1, group2)\n        print(f'''\nResponse rate for {g1}:1 - {group1.mean()}\nResponse rate for {g2}:1 - {group2.mean()}\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 1:1 - 0.020749124225276205\n    Response rate for 2:1 - 0.0226333752469912\n    t-statistic: -0.96504713432247\n    p-value: 0.33453168549723933\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 1:1 and 2:1 are equal.\n\n\n\ng1 = '2'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 2:1 - 0.0226333752469912\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -0.05011583793874515\n    p-value: 0.9600305283739325\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 2:1 and 3:1 are equal.\n\n\n\ng1 = '1'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 1:1 - 0.020749124225276205\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -1.0150255853798622\n    p-value: 0.3101046637086672\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 1:1 and 3:1 are equal.\n\n\n\nprobit_model2 = smf.probit('gave ~ ratio', data=df).fit()\nprint(probit_model2.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        17:53:16   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio[T.1]     0.0616      0.036      1.726      0.084      -0.008       0.132\nratio[T.2]     0.0980      0.035      2.792      0.005       0.029       0.167\nratio[T.3]     0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\n\n\n\ntreatment_df = df.loc[df.treatment == 1].copy()\ntreatment_df = treatment_df[['gave', 'ratio']].dropna()\ntreatment_df['ratio'] = pd.Categorical(\n    treatment_df['ratio'], \n    categories=['1', '2', '3'], \n    ordered=True\n)\nprint(treatment_df.groupby('ratio', observed=True)['gave'].mean())\n\nprobit_model3 = smf.probit('gave ~ ratio', data=treatment_df).fit()\nprint(probit_model3.summary())\n\nratio\n1    0.020749\n2    0.022633\n3    0.022733\nName: gave, dtype: float64\nOptimization terminated successfully.\n         Current function value: 0.105851\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                33396\nModel:                         Probit   Df Residuals:                    33393\nMethod:                           MLE   Df Model:                            2\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0001844\nTime:                        17:53:16   Log-Likelihood:                -3535.0\nconverged:                       True   LL-Null:                       -3535.6\nCovariance Type:            nonrobust   LLR p-value:                    0.5211\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.0385      0.027    -75.373      0.000      -2.092      -1.986\nratio[T.2]     0.0363      0.038      0.965      0.335      -0.037       0.110\nratio[T.3]     0.0382      0.038      1.015      0.310      -0.036       0.112\n==============================================================================\n\n\n\nprint(f'Difference between 3:1 response rate and 2:1 response rate: {ratio_df['3'] - ratio_df['2']}')\nprint(f'Difference between 2:1 response rate and 1:1 response rate: {ratio_df['2'] - ratio_df['1']}')\n\nDifference between 3:1 response rate and 2:1 response rate: 0.00010002398025293902\nDifference between 2:1 response rate and 1:1 response rate: 0.0018842510217149944\n\n\n\ncoefs = probit_model2.params\n\n# Coefficients: interpreted as difference from 'Control'\ncoef_1 = coefs['ratio[T.1]']\ncoef_2 = coefs['ratio[T.2]']\ncoef_3 = coefs['ratio[T.3]']\n\n# Compute pairwise differences between levels\ndiff_3_vs_2 = coef_3 - coef_2\ndiff_2_vs_1 = coef_2 - coef_1\n\nprint(f\"3:1 vs 2:1 difference (from regression): {diff_3_vs_2:.4f}\")\nprint(f\"2:1 vs 1:1 difference (from regression): {diff_2_vs_1:.4f}\")\n\n3:1 vs 2:1 difference (from regression): 0.0019\n2:1 vs 1:1 difference (from regression): 0.0363\n\n\n\nmfx = probit_model2.get_margeff()\nprint(mfx.summary())\n\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio[T.1]     0.0031      0.002      1.724      0.085      -0.000       0.007\nratio[T.2]     0.0049      0.002      2.786      0.005       0.001       0.008\nratio[T.3]     0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n\nmarginal_effects = mfx.margeff\nprint(\"Marginal effects by ratio level:\", marginal_effects)\n\n# Compare 2:1 to 1:1, 3:1 to 2:1\ndiff_2_vs_1 = marginal_effects[1] - marginal_effects[0]\ndiff_3_vs_2 = marginal_effects[2] - marginal_effects[1]\n\nprint(f\"Estimated increase from 1:1 to 2:1: {diff_2_vs_1:.4f}\")\nprint(f\"Estimated increase from 2:1 to 3:1: {diff_3_vs_2:.4f}\")\n\nMarginal effects by ratio level: [0.0030624  0.0048688  0.00496109]\nEstimated increase from 1:1 to 2:1: 0.0018\nEstimated increase from 2:1 to 3:1: 0.0001\n\n\n\ncontrol = df.loc[df.treatment == 0, 'amount'].dropna()\ntreatment = df.loc[df.treatment == 1, 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the donation amount of the two samples are equal.''')\n\n\nt-statistic: -1.8605020225753781\np-value: 0.06282038947470686\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the donation amount of the two samples are equal.\n\n\n\ncontrol = df.loc[(df.treatment == 0) & (df.gave == 1), 'amount'].dropna()\ntreatment = df.loc[(df.treatment == 1) & (df.gave == 1), 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the donation amount of the two samples are equal.''')\n\n\nt-statistic: 0.5808388615237938\np-value: 0.5614758782284279\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the donation amount of the two samples are equal.\n\n\n\ndonated_treatment = df.loc[(df.gave == 1) & (df.treatment == 1)].copy()\ndonated_control = df.loc[(df.gave == 1) & (df.treatment == 0)].copy()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\naxes[0].set_ylabel(\"Frequency\")\n\nfor val in [0, 1]:\n    subset = df.loc[(df.gave == 1) & (df.treatment == val)].copy()\n    axes[val].hist(subset['amount'], bins=10)\n    axes[val].axhline(y=subset['amount'].mean(), color='r', linestyle='--', label='Mean')\n    axes[val].legend()\n    axes[val].set_title(f'Amount Donated for {\"Treatment\" if val == 1 else \"Control\"} Group')\n    axes[val].set_xlabel(\"Dollars Donated\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nctr_p = 0.018\ntrt_p = 0.022\n\nnp.random.seed(12)\n\nsim_ctr = np.random.binomial(n=1, p=ctr_p, size=10_000)\nsim_trt = np.random.binomial(n=1, p=trt_p, size=10_000)\n\nsim_diff = sim_trt - sim_ctr\nsim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n\nprint(sim_diff.mean())\nprint(sim_diff_mean)\n\n0.005\n0.005000000000000001\n\n\n\ncumulative_avg = np.cumsum(sim_diff) / np.arange(1, len(sim_diff) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg)\nplt.axhline(y=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference (Treatment - Control)')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom cycler import cycler\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#375a7f']) \n\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10), sharey=True, sharex=True)\naxes = axes.flatten()\naxes[0].set_ylabel(\"Frequency\")\naxes[2].set_ylabel(\"Frequency\")\n\nfor ax, size in enumerate([50, 200, 500, 1000]):\n    samples = []\n    for i in range(1000):\n        sim_ctr = np.random.binomial(n=1, p=ctr_p, size=size)\n        sim_trt = np.random.binomial(n=1, p=trt_p, size=size)\n\n        sim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n        samples.append(sim_diff_mean)\n    \n    axes[ax].hist(samples, bins=10)\n    axes[ax].axvline(x=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\n    axes[ax].legend()\n    axes[ax].set_title(f'Average Difference from {size} Draws')\n    axes[ax].set_xlabel(\"Difference in Response Rate\")\n\n\nplt.tight_layout()\nplt.show()"
  }
]