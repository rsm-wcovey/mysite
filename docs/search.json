[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Last updated 04/05/2025"
  },
  {
    "objectID": "code/code_test.html",
    "href": "code/code_test.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "import hashlib\n\npw = 'bigbear'\nhpw = hashlib.sha256(pw.encode()).hexdigest()\nprint(hpw)\n\nf98f3d8cbcfa62aac83f1abb6411e40c5da9b2cf9ed67c0227b8675351a04500"
  },
  {
    "objectID": "projects/MGTA495/hw1.html",
    "href": "projects/MGTA495/hw1.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to either be a treatment letter with a matching donation offer or a control letter with no mention of matching donation. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nThe treatment group was further divided into various matching offer rates, either 1:1, 2:1, or 3:1 dollars matched to dollars donated. Of note, the organization donations were solicited for was a liberal nonprofit organization, and all potential donors mailed were previous donors to this organization. The experiment concluded that the presence of matching donation offers led to increased response rates and increased donation amounts, but no statistically significant increase was observed from higher match ratios.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/hw1.html#introduction",
    "href": "projects/MGTA495/hw1.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to either be a treatment letter with a matching donation offer or a control letter with no mention of matching donation. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nThe treatment group was further divided into various matching offer rates, either 1:1, 2:1, or 3:1 dollars matched to dollars donated. Of note, the organization donations were solicited for was a liberal nonprofit organization, and all potential donors mailed were previous donors to this organization. The experiment concluded that the presence of matching donation offers led to increased response rates and increased donation amounts, but no statistically significant increase was observed from higher match ratios.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/MGTA495/hw1.html#data",
    "href": "projects/MGTA495/hw1.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Summary\n\n\n\n\n\n\ndf = pd.read_stata('data/karlan_list_2007.dta')\ndf.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntreatment\n50083.0\n0.666813\n0.471357\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\ncontrol\n50083.0\n0.333187\n0.471357\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nratio2\n50083.0\n0.222311\n0.415803\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nratio3\n50083.0\n0.222211\n0.415736\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize25\n50083.0\n0.166723\n0.372732\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize50\n50083.0\n0.166623\n0.372643\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize100\n50083.0\n0.166723\n0.372732\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsizeno\n50083.0\n0.166743\n0.372750\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd1\n50083.0\n0.222311\n0.415803\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd2\n50083.0\n0.222291\n0.415790\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd3\n50083.0\n0.222211\n0.415736\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nask1\n50083.0\n71.501807\n101.728936\n25.000000\n35.000000\n45.000000\n65.000000\n1500.000000\n\n\nask2\n50083.0\n91.792724\n127.252628\n35.000000\n45.000000\n60.000000\n85.000000\n1875.000000\n\n\nask3\n50083.0\n111.046263\n151.673562\n50.000000\n55.000000\n70.000000\n100.000000\n2250.000000\n\n\namount\n50083.0\n0.915694\n8.707393\n0.000000\n0.000000\n0.000000\n0.000000\n400.000000\n\n\ngave\n50083.0\n0.020646\n0.142197\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\namountchange\n50083.0\n-52.672016\n1267.097656\n-200412.125000\n-50.000000\n-30.000000\n-25.000000\n275.000000\n\n\nhpa\n50083.0\n59.384975\n71.179871\n0.000000\n30.000000\n45.000000\n60.000000\n1000.000000\n\n\nltmedmra\n50083.0\n0.493720\n0.499966\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nfreq\n50083.0\n8.039355\n11.394454\n0.000000\n2.000000\n4.000000\n10.000000\n218.000000\n\n\nyears\n50082.0\n6.097540\n5.503492\n0.000000\n2.000000\n5.000000\n9.000000\n95.000000\n\n\nyear5\n50083.0\n0.508815\n0.499927\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nmrm2\n50082.0\n13.007268\n12.081403\n0.000000\n4.000000\n8.000000\n19.000000\n168.000000\n\n\ndormant\n50083.0\n0.523471\n0.499454\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nfemale\n48972.0\n0.277669\n0.447854\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\ncouple\n48935.0\n0.091897\n0.288884\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nstate50one\n50083.0\n0.000998\n0.031581\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nnonlit\n49631.0\n2.473918\n1.961528\n0.000000\n1.000000\n3.000000\n4.000000\n6.000000\n\n\ncases\n49631.0\n1.499768\n1.155140\n0.000000\n1.000000\n1.000000\n2.000000\n4.000000\n\n\nstatecnt\n50083.0\n5.998820\n5.745993\n0.001995\n1.833234\n3.538799\n9.607021\n17.368841\n\n\nstateresponse\n50083.0\n0.020627\n0.005171\n0.000000\n0.018163\n0.019710\n0.023048\n0.076923\n\n\nstateresponset\n50083.0\n0.021989\n0.006257\n0.000000\n0.018493\n0.021697\n0.024703\n0.111111\n\n\nstateresponsec\n50080.0\n0.017717\n0.007516\n0.000000\n0.012862\n0.019881\n0.020806\n0.052632\n\n\nstateresponsetminc\n50080.0\n0.004273\n0.009112\n-0.047619\n-0.001388\n0.001779\n0.010545\n0.111111\n\n\nperbush\n50048.0\n0.487940\n0.078733\n0.090909\n0.444444\n0.484848\n0.525253\n0.731959\n\n\nclose25\n50048.0\n0.185702\n0.388870\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nred0\n50048.0\n0.404452\n0.490791\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nblue0\n50048.0\n0.595548\n0.490791\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nredcty\n49978.0\n0.510245\n0.499900\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nbluecty\n49978.0\n0.488715\n0.499878\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\npwhite\n48217.0\n0.819599\n0.168560\n0.009418\n0.755845\n0.872797\n0.938827\n1.000000\n\n\npblack\n48047.0\n0.086710\n0.135868\n0.000000\n0.014729\n0.036554\n0.090882\n0.989622\n\n\npage18_39\n48217.0\n0.321694\n0.103039\n0.000000\n0.258311\n0.305534\n0.369132\n0.997544\n\n\nave_hh_sz\n48221.0\n2.429012\n0.378105\n0.000000\n2.210000\n2.440000\n2.660000\n5.270000\n\n\nmedian_hhincome\n48209.0\n54815.700533\n22027.316665\n5000.000000\n39181.000000\n50673.000000\n66005.000000\n200001.000000\n\n\npowner\n48214.0\n0.669418\n0.193405\n0.000000\n0.560222\n0.712296\n0.816798\n1.000000\n\n\npsch_atlstba\n48215.0\n0.391661\n0.186599\n0.000000\n0.235647\n0.373744\n0.530036\n1.000000\n\n\npop_propurban\n48217.0\n0.871968\n0.258633\n0.000000\n0.884929\n1.000000\n1.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\ntest_variables = ['hpa', 'freq', 'years', 'median_hhincome']\n\nfor var in test_variables:\n    control = df.loc[df.treatment == 0, var].dropna()\n    treatment = df.loc[df.treatment == 1, var].dropna()\n\n    t_stat_manual = np.divide(\n        (control.mean() - treatment.mean()),\n        np.sqrt(\n            (treatment.var(ddof=1) / len(treatment)) +\n            (control.var(ddof=1) / len(control))\n        )\n    )\n    pval_manual = 2 * (1 - t.cdf(np.abs(t_stat_manual), df=len(control) + len(treatment) - 2))\n\n    t_stat, pval = ttest_ind(control, treatment)\n    print(f'''\nT-test Results for {var}:\n\nControl mean: {control.mean()}\nTreatment mean: {treatment.mean()}\n\nt-statistic (manual): {t_stat_manual}\nt-statistic (scipy): {t_stat}\np-value (manual): {pval_manual}\np-value (scipy): {pval}\n''')\n    m = rsm.model.regress(data=df,\n                      rvar=var,\n                      evar=['treatment'],\n    )\n    print(f'Linear Regression Results for {var}:')\n\n    print(m.summary(main=False))\n    print(f'''\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the mean value from the two samples are equal.\n---------------------------------------------------''')\n\n\nT-test Results for hpa:\n\nControl mean: 58.960166931152344\nTreatment mean: 59.59724044799805\n\nt-statistic (manual): -0.9703896722043864\nt-statistic (scipy): -0.944145044786662\np-value (manual): 0.33185698112371353\np-value (scipy): 0.34510008823759086\n\nLinear Regression Results for hpa:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.891 df(1, 50081), p.value 0.345\nNr obs: 50,083\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test Results for freq:\n\nControl mean: 8.047342242464193\nTreatment mean: 8.035363516588813\n\nt-statistic (manual): 0.11084502380904246\nt-statistic (scipy): 0.11089297035979982\np-value (manual): 0.9117396856546793\np-value (scipy): 0.9117016644344591\n\nLinear Regression Results for freq:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test Results for years:\n\nControl mean: 6.1359141846946725\nTreatment mean: 6.078365024704297\n\nt-statistic (manual): 1.0909175279573782\nt-statistic (scipy): 1.103038374578911\np-value (manual): 0.2753144222756161\np-value (scipy): 0.27001580108724454\n\nLinear Regression Results for years:\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 1.217 df(1, 50080), p.value 0.27\nNr obs: 50,082\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test Results for median_hhincome:\n\nControl mean: 54921.09447493141\nTreatment mean: 54763.168992633575\n\nt-statistic (manual): 0.7432960510660361\nt-statistic (scipy): 0.741683012117828\np-value (manual): 0.4573060841853336\np-value (scipy): 0.458283028000566\n\nLinear Regression Results for median_hhincome:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.55 df(1, 48207), p.value 0.458\nNr obs: 48,209\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\n\nConfirmed through manual t-test calculation, t-tests performed with scipy, and with linear regression models, none of the assessed variables are statistically significantly different between the control and treatment groups."
  },
  {
    "objectID": "projects/MGTA495/hw1.html#experimental-results",
    "href": "projects/MGTA495/hw1.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\ngave_df = df.groupby('treatment')['gave'].mean()\ngave_df.index = gave_df.index.map({0: 'Control', 1: 'Treatment'})\n\nplt.bar(gave_df.index, gave_df.values)\nplt.title('Proportion Who Donated by Group')\nplt.xlabel('Group')\nplt.ylabel('Proportion Who Donated')\nfor i, v in enumerate(gave_df.values):\n    plt.text(i, v-0.001, f\"{v:.3f}\", ha='center', color='white')\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol = df.loc[df.treatment == 0, 'gave'].dropna()\ntreatment = df.loc[df.treatment == 1, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test Results: \n\nControl mean: {control.mean()}\nTreatment mean: {treatment.mean()}\n\nt-statistic: {t_stat}\np-value: {pval}''')\n\nprobit_model = smf.probit('gave ~ treatment', data=df).fit(disp=False)\nprint(f'''\nProbit Regression Results:\n      \nt-statistic: {probit_model.tvalues['treatment']}\np-value: {probit_model.pvalues['treatment']}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the mean value from the two samples are equal.\n''')\n\n\nT-test Results: \n\nControl mean: 0.017858212980164198\nTreatment mean: 0.02203856749311295\n\nt-statistic: -3.101361000543946\np-value: 0.0019274025949016982\n\nProbit Regression Results:\n      \nt-statistic: 3.1129300737950434\np-value: 0.0018523990147782177\n\nAt the 95% confidence level, we reject the null hypothesis \nthat the mean value from the two samples are equal.\n\n\n\nFrom both the t-test and the probit regression model, we find a statistically significant difference between the response rates (average value for binary ‚Äògave‚Äô variable) from the control and treatment samples at the 99% confidence level. From this, we can conclude that potential donors are more likely to respond to solicitation and donate when provided an offer of matching donation contributions.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ndf['ratio'] = df['ratio'].astype(str)\ndf['ratio'] = pd.Categorical(\n    df['ratio'], categories=['Control', '1', '2', '3'], ordered=True\n)\nratio_df = df.groupby('ratio', observed=False)['gave'].mean()\n\nratios = ratio_df.index.values[1:]\nfor i in range(len((ratios))):\n\n    r1 = ratios[i]\n    r2 = ratios[i + 1] if i + 1 &lt; len(ratios) else ratios[0]\n\n    group1 = df.loc[df.ratio == r1, 'gave'].dropna()\n    group2 = df.loc[df.ratio == r2, 'gave'].dropna()\n\n    t_stat, pval = ttest_ind(group1, group2)\n    print(f'''\nResponse rate for {r1}:1  {group1.mean()}\nResponse rate for {r2}:1  {group2.mean()}\n\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the response rate of ratios {r1}:1 and {r2}:1 are equal.\n---------------------------------------------------''')\n\n\nResponse rate for 1:1  0.020749124225276205\nResponse rate for 2:1  0.0226333752469912\n\nt-statistic: -0.96504713432247\np-value: 0.33453168549723933\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the response rate of ratios 1:1 and 2:1 are equal.\n---------------------------------------------------\n\nResponse rate for 2:1  0.0226333752469912\nResponse rate for 3:1  0.022733399227244138\n\nt-statistic: -0.05011583793874515\np-value: 0.9600305283739325\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the response rate of ratios 2:1 and 3:1 are equal.\n---------------------------------------------------\n\nResponse rate for 3:1  0.022733399227244138\nResponse rate for 1:1  0.020749124225276205\n\nt-statistic: 1.0150255853798622\np-value: 0.3101046637086672\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the response rate of ratios 3:1 and 1:1 are equal.\n---------------------------------------------------\n\n\nAs seen through the above series of t-tests, comparing the mean response rates between varying match ratio samples, increasing match ratios above 1:1 has no significant impact on response rates. This affirms the conclusion made by the authors of the study.\n\nResponse Rate Regressed on Match Ratio (from full dataset):\n\nprobit_model2 = smf.probit('gave ~ ratio', data=df).fit(disp=False)\n\npm2_df = pd.DataFrame({\n    'coef': probit_model2.params,\n    't-stat': probit_model2.tvalues,\n    'pval': probit_model2.pvalues\n})\ndisplay(pm2_df)\n\n\n\n\n\n\n\n\ncoef\nt-stat\npval\n\n\n\n\nIntercept\n-2.100141\n-90.072770\n0.000000\n\n\nratio[T.1]\n0.061624\n1.725748\n0.084393\n\n\nratio[T.2]\n0.097974\n2.792255\n0.005234\n\n\nratio[T.3]\n0.099831\n2.847311\n0.004409\n\n\n\n\n\n\n\nThe large negative coefficient on the intercept demonstrates the relatively low probability of response for the control group, where the positive coefficients combined with low p-values, particularly for 2:1 and 3:1 match rates, demonstrate the statistically significant increase that the treatment has on respones rates. To further asses the difference between match rates, I will run the regression again, excluding the control group.\n\n\nResponse Rate Regressed on Match Ratio (from treatment group only):\n\ntreatment_df = df.loc[df.treatment == 1]\ntreatment_df = treatment_df[['gave', 'ratio']].dropna()\ntreatment_df['ratio'] = pd.Categorical(\n    treatment_df['ratio'], categories=['1', '2', '3'], ordered=True\n)\n\nprobit_model3 = smf.probit('gave ~ ratio', data=treatment_df).fit(disp=False)\n\npm3_df = pd.DataFrame({\n    'coef': probit_model3.params,\n    't-stat': probit_model3.tvalues,\n    'pval': probit_model3.pvalues\n})\ndisplay(pm3_df)\n\n\n\n\n\n\n\n\ncoef\nt-stat\npval\n\n\n\n\nIntercept\n-2.038517\n-75.373213\n0.000000\n\n\nratio[T.2]\n0.036350\n0.964972\n0.334559\n\n\nratio[T.3]\n0.038207\n1.014933\n0.310138\n\n\n\n\n\n\n\nWith the control group excluded, we can see from the high p-values on the coefficients for 2:1 and 3:1 match ratios that they do not have a significantly different impact on response rates from the intercept (1:1).\n\nprint(f'Observed difference between 3:1 response rate and 2:1 response rate: {ratio_df['3'] - ratio_df['2']}')\nprint(f'Observed difference between 2:1 response rate and 1:1 response rate: {ratio_df['2'] - ratio_df['1']}')\n\nmfx = probit_model2.get_margeff()\nmarginal_effects = mfx.margeff\ndiff_3_vs_2 = marginal_effects[2] - marginal_effects[1]\ndiff_2_vs_1 = marginal_effects[1] - marginal_effects[0]\n\nprint(f\"Estimated difference between 3:1 response rate and 2:1 response rate: {diff_3_vs_2}\")\nprint(f\"Estimated difference between 2:1 response rate and 1:1 response rate: {diff_2_vs_1}\")\n\nObserved difference between 3:1 response rate and 2:1 response rate: 0.00010002398025293902\nObserved difference between 2:1 response rate and 1:1 response rate: 0.0018842510217149944\nEstimated difference between 3:1 response rate and 2:1 response rate: 9.229335508974864e-05\nEstimated difference between 2:1 response rate and 1:1 response rate: 0.0018064011975636126\n\n\nThe analysis continues to affirm the authors‚Äô findings that beyond adding a matching donation of any size, increasing match ratios is not an effective method of driving higher response rates.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ncontrol = df.loc[df.treatment == 0, 'amount'].dropna()\ntreatment = df.loc[df.treatment == 1, 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test Results:\n      \nControl mean: ${control.mean():,.2f}\nTreatment mean: ${treatment.mean():,.2f}\n      \nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the mean donation amount of the two samples are equal.''')\n\n\nT-test Results:\n      \nControl mean: $0.81\nTreatment mean: $0.97\n      \nt-statistic: -1.8605020225753781\np-value: 0.06282038947470686\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the mean donation amount of the two samples are equal.\n\n\nWe can observe that the treatment group has a higher mean donation amount, as identified by the authors, but at the 95% confidence level, it is not statistically significant.\n\ncontrol = df.loc[(df.treatment == 0) & (df.gave == 1), 'amount'].dropna()\ntreatment = df.loc[(df.treatment == 1) & (df.gave == 1), 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test Results:\n      \nControl mean: ${control.mean():,.2f}\nTreatment mean: ${treatment.mean():,.2f}\n\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis \nthat the donation amount of the two samples are equal.''')\n\n\nT-test Results:\n      \nControl mean: $45.54\nTreatment mean: $43.87\n\nt-statistic: 0.5808388615237938\np-value: 0.5614758782284279\n\nAt the 95% confidence level, we fail to reject the null hypothesis \nthat the donation amount of the two samples are equal.\n\n\nAssessing only those who made a donation, we in fact see that the mean donation amount among the treatment group is lower than the control group, though with a much higher p-value than the previous t-test. It appears that while the treatment results in higher response rates, most of those donors who are ‚Äòconverted‚Äô by the treatment are making smaller donations than those who donated from the control group.\n\nfig, axes = plt.subplots(1, 2, figsize=(7.8, 3.9), sharey=True)\naxes[0].set_ylabel(\"Frequency\")\n\nfor val in [0, 1]:\n    subset = df.loc[(df.gave == 1) & (df.treatment == val)].copy()\n    axes[val].hist(subset['amount'], bins=10)\n    axes[val].axvline(x=subset['amount'].mean(), color='r', linestyle='--', label=f'Mean: ${subset[\"amount\"].mean():,.2f}')\n    axes[val].legend()\n    axes[val].set_title(f'Amount Donated for {\"Treatment\" if val == 1 else \"Control\"} Group')\n    axes[val].set_xlabel(\"Dollars Donated\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/MGTA495/hw1.html#simulation-experiment",
    "href": "projects/MGTA495/hw1.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic ‚Äúworks,‚Äù in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe below chart illustrates the cumulative average difference in response rates from 10,000 draws of simulated treatment and control distributions. In early simulations, we see this cumulative average move erratically due to random variation, but as more draws are simulated, the average begins to stabilize and converge toward the true observed treatment effect of approximately 0.004.\n\nctr_p = 0.018\ntrt_p = 0.022\n\nnp.random.seed(12)\nsim_ctr = np.random.binomial(n=1, p=ctr_p, size=10_000)\nsim_trt = np.random.binomial(n=1, p=trt_p, size=10_000)\n\nsim_diff = sim_trt - sim_ctr\ncumulative_avg = np.cumsum(sim_diff) / np.arange(1, len(sim_diff) + 1)\n\nplt.figure(figsize=(7.8, 3.9))\nplt.plot(cumulative_avg)\nplt.axhline(y=trt_p - ctr_p, color='red', linestyle='--', label=f'True Effect ({trt_p-ctr_p:.3f})')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulated Draws')\nplt.ylabel('Cum. Avg. Difference (Treatment - Control)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nThese histograms show the distribution of simulated average differences in response rates between treatment and control groups at sample sizes of 50, 200, 500, and 1000. As the sample size increases, the distributions become tighter and more symmetric, demonstrating the central limit theorem: larger samples yield more stable, normally distributed estimates.\n\nfig, axes = plt.subplots(2, 2, figsize=(7.8, 7.8), sharey=True, sharex=True)\naxes = axes.flatten()\naxes[0].set_ylabel(\"Frequency\")\naxes[2].set_ylabel(\"Frequency\")\naxes[2].set_xlabel(\"Difference in Response Rate\")\naxes[3].set_xlabel(\"Difference in Response Rate\")\n\nfor ax, size in enumerate([50, 200, 500, 1000]):\n    samples = []\n    for i in range(1000):\n        sim_ctr = np.random.binomial(n=1, p=ctr_p, size=size)\n        sim_trt = np.random.binomial(n=1, p=trt_p, size=size)\n\n        sim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n        samples.append(sim_diff_mean)\n    \n    axes[ax].hist(samples, bins=np.linspace(-0.02, 0.03, 11))\n    axes[ax].axvline(x=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\n    axes[ax].legend()\n    axes[ax].set_title(f'Average Difference from {size} Draws')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/school/hw3.html",
    "href": "projects/school/hw3.html",
    "title": "Example 2",
    "section": "",
    "text": "##Example 2\nExample histogram below:\nThis is a protected section. Here‚Äôs a Python-generated histogram:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(100)\nplt.hist(x)\nplt.show()"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Logos used on this site are the property of their respective owners. No endorsement or affiliation is implied. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 1\n\n\n\nApr 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\n\n\n\nApr 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSan Diego Real Estate Shiny App\n\n\n\nNov 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample Power BI Report\n\n\n\nJun 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "bonus.html",
    "href": "bonus.html",
    "title": "Rex",
    "section": "",
    "text": "ü¶ñüåµ\n\n\nScore: 0\n\n\n\n Jump!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "Wesley is a data-driven operations analyst and Marine Corps veteran with a proven record of turning complex data into actionable insights. With experience spanning financial analytics, business intelligence, and process optimization, he brings precision and purpose to every challenge. Outside of work, he enjoys gardening, woodworking, and exploring San Diego‚Äôs hiking trails.\n\n\nUniversity of California, San Diego - Rady School of Management | M.S. in Business Analytics | 2024 - Present\nArizona State University - W.P. Carey School of Business | B.S. in Economics | 2018 - 2023\n\n\n\nAcademy Securities | Operations Analyst | 2023 - Present\nUnited States Marine Corps | Chief Force Deployment Analyst | 2015 - 2023"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "University of California, San Diego - Rady School of Management | M.S. in Business Analytics | 2024 - Present\nArizona State University - W.P. Carey School of Business | B.S. in Economics | 2018 - 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Wesley D. Covey",
    "section": "",
    "text": "Academy Securities | Operations Analyst | 2023 - Present\nUnited States Marine Corps | Chief Force Deployment Analyst | 2015 - 2023"
  },
  {
    "objectID": "projects/work/shiny_real_estate.html",
    "href": "projects/work/shiny_real_estate.html",
    "title": "San Diego Real Estate Shiny App",
    "section": "",
    "text": "Here is where I will enter my project notes.\n\nClick here to open the app in a new tab."
  },
  {
    "objectID": "projects/work/shiny_real_estate.html#project-notes",
    "href": "projects/work/shiny_real_estate.html#project-notes",
    "title": "San Diego Real Estate Shiny App",
    "section": "",
    "text": "Here is where I will enter my project notes.\n\nClick here to open the app in a new tab."
  },
  {
    "objectID": "projects/school/hw1.html",
    "href": "projects/school/hw1.html",
    "title": "Example 1",
    "section": "",
    "text": "Example dataframe below:\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"A\": [1, 2, 3],\n    \"B\": [4, 5, 6]\n})\n\nprint(df)\n\n   A  B\n0  1  4\n1  2  5\n2  3  6"
  },
  {
    "objectID": "projects/MGTA495/hw1_nb.html",
    "href": "projects/MGTA495/hw1_nb.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind, t\nimport pyrsm as rsm\nimport matplotlib.pyplot as plt\nfrom cycler import cycler\n\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#375a7f']) \n\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\ndf.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntreatment\n50083.0\n0.666813\n0.471357\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\ncontrol\n50083.0\n0.333187\n0.471357\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nratio2\n50083.0\n0.222311\n0.415803\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nratio3\n50083.0\n0.222211\n0.415736\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize25\n50083.0\n0.166723\n0.372732\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize50\n50083.0\n0.166623\n0.372643\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsize100\n50083.0\n0.166723\n0.372732\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nsizeno\n50083.0\n0.166743\n0.372750\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd1\n50083.0\n0.222311\n0.415803\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd2\n50083.0\n0.222291\n0.415790\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\naskd3\n50083.0\n0.222211\n0.415736\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nask1\n50083.0\n71.501807\n101.728936\n25.000000\n35.000000\n45.000000\n65.000000\n1500.000000\n\n\nask2\n50083.0\n91.792724\n127.252628\n35.000000\n45.000000\n60.000000\n85.000000\n1875.000000\n\n\nask3\n50083.0\n111.046263\n151.673562\n50.000000\n55.000000\n70.000000\n100.000000\n2250.000000\n\n\namount\n50083.0\n0.915694\n8.707393\n0.000000\n0.000000\n0.000000\n0.000000\n400.000000\n\n\ngave\n50083.0\n0.020646\n0.142197\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\namountchange\n50083.0\n-52.672016\n1267.097656\n-200412.125000\n-50.000000\n-30.000000\n-25.000000\n275.000000\n\n\nhpa\n50083.0\n59.384975\n71.179871\n0.000000\n30.000000\n45.000000\n60.000000\n1000.000000\n\n\nltmedmra\n50083.0\n0.493720\n0.499966\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nfreq\n50083.0\n8.039355\n11.394454\n0.000000\n2.000000\n4.000000\n10.000000\n218.000000\n\n\nyears\n50082.0\n6.097540\n5.503492\n0.000000\n2.000000\n5.000000\n9.000000\n95.000000\n\n\nyear5\n50083.0\n0.508815\n0.499927\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nmrm2\n50082.0\n13.007268\n12.081403\n0.000000\n4.000000\n8.000000\n19.000000\n168.000000\n\n\ndormant\n50083.0\n0.523471\n0.499454\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nfemale\n48972.0\n0.277669\n0.447854\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\ncouple\n48935.0\n0.091897\n0.288884\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nstate50one\n50083.0\n0.000998\n0.031581\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nnonlit\n49631.0\n2.473918\n1.961528\n0.000000\n1.000000\n3.000000\n4.000000\n6.000000\n\n\ncases\n49631.0\n1.499768\n1.155140\n0.000000\n1.000000\n1.000000\n2.000000\n4.000000\n\n\nstatecnt\n50083.0\n5.998820\n5.745993\n0.001995\n1.833234\n3.538799\n9.607021\n17.368841\n\n\nstateresponse\n50083.0\n0.020627\n0.005171\n0.000000\n0.018163\n0.019710\n0.023048\n0.076923\n\n\nstateresponset\n50083.0\n0.021989\n0.006257\n0.000000\n0.018493\n0.021697\n0.024703\n0.111111\n\n\nstateresponsec\n50080.0\n0.017717\n0.007516\n0.000000\n0.012862\n0.019881\n0.020806\n0.052632\n\n\nstateresponsetminc\n50080.0\n0.004273\n0.009112\n-0.047619\n-0.001388\n0.001779\n0.010545\n0.111111\n\n\nperbush\n50048.0\n0.487940\n0.078733\n0.090909\n0.444444\n0.484848\n0.525253\n0.731959\n\n\nclose25\n50048.0\n0.185702\n0.388870\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n\n\nred0\n50048.0\n0.404452\n0.490791\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\nblue0\n50048.0\n0.595548\n0.490791\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nredcty\n49978.0\n0.510245\n0.499900\n0.000000\n0.000000\n1.000000\n1.000000\n1.000000\n\n\nbluecty\n49978.0\n0.488715\n0.499878\n0.000000\n0.000000\n0.000000\n1.000000\n1.000000\n\n\npwhite\n48217.0\n0.819599\n0.168560\n0.009418\n0.755845\n0.872797\n0.938827\n1.000000\n\n\npblack\n48047.0\n0.086710\n0.135868\n0.000000\n0.014729\n0.036554\n0.090882\n0.989622\n\n\npage18_39\n48217.0\n0.321694\n0.103039\n0.000000\n0.258311\n0.305534\n0.369132\n0.997544\n\n\nave_hh_sz\n48221.0\n2.429012\n0.378105\n0.000000\n2.210000\n2.440000\n2.660000\n5.270000\n\n\nmedian_hhincome\n48209.0\n54815.700533\n22027.316665\n5000.000000\n39181.000000\n50673.000000\n66005.000000\n200001.000000\n\n\npowner\n48214.0\n0.669418\n0.193405\n0.000000\n0.560222\n0.712296\n0.816798\n1.000000\n\n\npsch_atlstba\n48215.0\n0.391661\n0.186599\n0.000000\n0.235647\n0.373744\n0.530036\n1.000000\n\n\npop_propurban\n48217.0\n0.871968\n0.258633\n0.000000\n0.884929\n1.000000\n1.000000\n1.000000\n\n\n\n\n\n\n\n\ntest_variables = ['hpa', 'freq', 'female', 'redcty', 'bluecty']\n\nfor var in test_variables:\n    control = df.loc[df.treatment == 0, var].dropna()\n    treatment = df.loc[df.treatment == 1, var].dropna()\n\n    t_stat_manual = np.divide(\n        (control.mean() - treatment.mean()),\n        np.sqrt(\n            (treatment.var(ddof=1) / len(treatment)) +\n            (control.var(ddof=1) / len(control))\n        )\n    )\n    pval_manual = 2 * (1 - t.cdf(np.abs(t_stat_manual), df=len(control) + len(treatment) - 2))\n\n    t_stat, pval = ttest_ind(control, treatment)\n    print(f'''\nT-test results for {var}:\n\nt-statistic (manual): {t_stat_manual}\nt-statistic (scipy): {t_stat}\np-value (manual): {pval_manual}\np-value (scipy): {pval}\n''')\n    m = rsm.model.regress(data=df,\n                      rvar=var,\n                      evar=['treatment'],\n    )\n    print(f'Linear regression results for {var}:')\n\n    print(m.summary(main=False))\n    print(f'''\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------''')\n\n\nT-test results for hpa:\n\nt-statistic (manual): -0.9703896722043864\nt-statistic (scipy): -0.944145044786662\np-value (manual): 0.33185698112371353\np-value (scipy): 0.34510008823759086\n\nLinear regression results for hpa:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.891 df(1, 50081), p.value 0.345\nNr obs: 50,083\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test results for freq:\n\nt-statistic (manual): 0.11084502380904246\nt-statistic (scipy): 0.11089297035979982\np-value (manual): 0.9117396856546793\np-value (scipy): 0.9117016644344591\n\nLinear regression results for freq:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test results for female:\n\nt-statistic (manual): 1.7535132542518672\nt-statistic (scipy): 1.7583691871450704\np-value (manual): 0.0795202022086543\np-value (scipy): 0.07869095826986476\n\nLinear regression results for female:\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test results for redcty:\n\nt-statistic (manual): -0.9041328879393103\nt-statistic (scipy): -0.9041867297482356\np-value (manual): 0.3659292994478305\np-value (scipy): 0.3659007540247129\n\nLinear regression results for redcty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.818 df(1, 49976), p.value 0.366\nNr obs: 49,978\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\nT-test results for bluecty:\n\nt-statistic (manual): 0.8534850504225705\nt-statistic (scipy): 0.8535382534940722\np-value (manual): 0.3933944650906658\np-value (scipy): 0.3933649744168656\n\nLinear regression results for bluecty:\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978\nNone\n\nAt the 95% confidence level, we fail to reject the null hypothesis\nthat the mean value from the two samples are equal.\n---------------------------------------------------\n\n\nThe results of the t-test and linear regression analysis on these explanatory variables affirm that that treatment and control groups are not statistically significantly different, at the 95% confidence level.\n\ngave_df = df.groupby('treatment')['gave'].mean()\ngave_df.index = gave_df.index.map({0: 'Control', 1: 'Treatment'})\n\nplt.bar(gave_df.index, gave_df.values)\nplt.title('Proportion Who Donated by Group')\nplt.xlabel('Group')\nplt.ylabel('Proportion Who Donated')\nfor i, v in enumerate(gave_df.values):\n    plt.text(i, v-0.001, f\"{v:.3f}\", ha='center', color='white')\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol = df.loc[df.treatment == 0, 'gave'].dropna()\ntreatment = df.loc[df.treatment == 1, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null hypothesis that the response rate of the two samples are equal.''')\n\n\nt-statistic: -3.101361000543946\np-value: 0.0019274025949016982\n\nAt the 95% confidence level, we reject the null hypothesis that the response rate of the two samples are equal.\n\n\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\nprint(f'''Probit Regression Results:\n      \nt-statistic: {probit_model.tvalues['treatment']}\np-value: {probit_model.pvalues['treatment']}''')\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\nProbit Regression Results:\n      \nt-statistic: 3.1129300737950434\np-value: 0.0018523990147782177\n\n\nGiven the low p-value from both the t-test and probit regression, we can conclude that people are more likely to respond to a request for charitable donations when informed that their donations will be met with a matching donation.\n\ndf['ratio'] = df['ratio'].astype(str)\ndf['ratio'] = pd.Categorical(\n    df['ratio'], categories=['Control', '1', '2', '3'], ordered=True\n    )\n\n\nratio_df = df.groupby('ratio')['gave'].mean()\ndisplay(ratio_df)\n\n/tmp/ipykernel_27584/157019139.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ratio_df = df.groupby('ratio')['gave'].mean()\n\n\nratio\nControl    0.017858\n1          0.020749\n2          0.022633\n3          0.022733\nName: gave, dtype: float64\n\n\n\nratios = ratio_df.index.values[1:]\nratios\n\n['1', '2', '3']\nCategories (4, object): ['Control' &lt; '1' &lt; '2' &lt; '3']\n\n\n\nratios = ratio_df.index.values[1:]\nfor i in range(len((ratios))):\n\n    r1 = ratios[i]\n    r2 = ratios[i + 1] if i + 1 &lt; len(ratios) else ratios[0]\n\n    group1 = df.loc[df.ratio == r1, 'gave'].dropna()\n    group2 = df.loc[df.ratio == r2, 'gave'].dropna()\n\n    t_stat, pval = ttest_ind(group1, group2)\n    print(f'''\nResponse rate for {r1}:1  {group1.mean()}\nResponse rate for {r2}:1  {group2.mean()}\n\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null \nhypothesis that the response rate of ratios {r1}:1 and {r2}:1 are equal.\n---------------------------------------------------''')\n\n\nResponse rate for 1:1  0.020749124225276205\nResponse rate for 2:1  0.0226333752469912\n\nt-statistic: -0.96504713432247\np-value: 0.33453168549723933\n\nAt the 95% confidence level, we fail to reject the null \nhypothesis that the response rate of ratios 1:1 and 2:1 are equal.\n---------------------------------------------------\n\nResponse rate for 2:1  0.0226333752469912\nResponse rate for 3:1  0.022733399227244138\n\nt-statistic: -0.05011583793874515\np-value: 0.9600305283739325\n\nAt the 95% confidence level, we fail to reject the null \nhypothesis that the response rate of ratios 2:1 and 3:1 are equal.\n---------------------------------------------------\n\nResponse rate for 3:1  0.022733399227244138\nResponse rate for 1:1  0.020749124225276205\n\nt-statistic: 1.0150255853798622\np-value: 0.3101046637086672\n\nAt the 95% confidence level, we fail to reject the null \nhypothesis that the response rate of ratios 3:1 and 1:1 are equal.\n---------------------------------------------------\n\n\n\ng1 = '2'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 2:1 - 0.0226333752469912\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -0.05011583793874515\n    p-value: 0.9600305283739325\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 2:1 and 3:1 are equal.\n\n\n\ng1 = '1'\ng2 = '3'\n\ngroup1 = df.loc[df.ratio == g1, 'gave'].dropna()\ngroup2 = df.loc[df.ratio == g2, 'gave'].dropna()\n\nt_stat, pval = ttest_ind(group1, group2)\nprint(f'''\n    Response rate for {g1}:1 - {group1.mean()}\n    Response rate for {g2}:1 - {group2.mean()}\n    t-statistic: {t_stat}\n    p-value: {pval}\n\n    At the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} \n    the null hypothesis that the response rate of ratio {g1}:1 and {g2}:1 are equal.''')\n\n\n    Response rate for 1:1 - 0.020749124225276205\n    Response rate for 3:1 - 0.022733399227244138\n    t-statistic: -1.0150255853798622\n    p-value: 0.3101046637086672\n\n    At the 95% confidence level, we fail to reject \n    the null hypothesis that the response rate of ratio 1:1 and 3:1 are equal.\n\n\n\nprobit_model2 = smf.probit('gave ~ ratio', data=df).fit()\n\nprint(f'''\ncoefficients: \n{probit_model2.params}\n\nt-statistic: \n{probit_model2.tvalues}\n\np-value: \n{probit_model2.pvalues}''')\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n\ncoefficients: \nIntercept    -2.100141\nratio[T.1]    0.061624\nratio[T.2]    0.097974\nratio[T.3]    0.099831\ndtype: float64\n\nt-statistic: \nIntercept    -90.072770\nratio[T.1]     1.725748\nratio[T.2]     2.792255\nratio[T.3]     2.847311\ndtype: float64\n\np-value: \nIntercept     0.000000\nratio[T.1]    0.084393\nratio[T.2]    0.005234\nratio[T.3]    0.004409\ndtype: float64\n\n\n\nfor param, coef, tval, pval in zip(\n    probit_model2.params.index,\n    probit_model2.params.values,\n    probit_model2.tvalues,\n    probit_model2.pvalues\n):\n    print(f\"{param:&lt;15}  coef: {coef:&gt;8.4f}  t-stat: {tval:&gt;8.3f}  pval: {pval:&gt;8.4f}\")\n\nIntercept        coef:  -2.1001  t-stat:  -90.073  pval:   0.0000\nratio[T.1]       coef:   0.0616  t-stat:    1.726  pval:   0.0844\nratio[T.2]       coef:   0.0980  t-stat:    2.792  pval:   0.0052\nratio[T.3]       coef:   0.0998  t-stat:    2.847  pval:   0.0044\n\n\n\npm2_df = pd.DataFrame({\n    'coef': probit_model2.params,\n    't-stat': probit_model2.tvalues,\n    'pval': probit_model2.pvalues\n})\n\ndisplay(pm2_df)\n\n\n\n\n\n\n\n\ncoef\nt-stat\npval\n\n\n\n\nIntercept\n-2.100141\n-90.072770\n0.000000\n\n\nratio[T.1]\n0.061624\n1.725748\n0.084393\n\n\nratio[T.2]\n0.097974\n2.792255\n0.005234\n\n\nratio[T.3]\n0.099831\n2.847311\n0.004409\n\n\n\n\n\n\n\n\ntreatment_df = df.loc[df.treatment == 1]\ntreatment_df = treatment_df[['gave', 'ratio']].dropna()\ntreatment_df['ratio'] = pd.Categorical(\n    treatment_df['ratio'], categories=['1', '2', '3'], ordered=True\n)\n\nprobit_model3 = smf.probit('gave ~ ratio', data=treatment_df).fit(disp=False)\n\npm3_df = pd.DataFrame({\n    'coef': probit_model3.params,\n    't-stat': probit_model3.tvalues,\n    'pval': probit_model3.pvalues\n})\ndisplay(pm3_df)\n\n\n\n\n\n\n\n\ncoef\nt-stat\npval\n\n\n\n\nIntercept\n-2.038517\n-75.373213\n0.000000\n\n\nratio[T.2]\n0.036350\n0.964972\n0.334559\n\n\nratio[T.3]\n0.038207\n1.014933\n0.310138\n\n\n\n\n\n\n\n\nprint(f'Difference between 3:1 response rate and 2:1 response rate: {ratio_df['3'] - ratio_df['2']}')\nprint(f'Difference between 2:1 response rate and 1:1 response rate: {ratio_df['2'] - ratio_df['1']}')\n\nDifference between 3:1 response rate and 2:1 response rate: 0.00010002398025293902\nDifference between 2:1 response rate and 1:1 response rate: 0.0018842510217149944\n\n\n\ncoefs = probit_model2.params\n\n# Coefficients: interpreted as difference from 'Control'\ncoef_1 = coefs['ratio[T.1]']\ncoef_2 = coefs['ratio[T.2]']\ncoef_3 = coefs['ratio[T.3]']\n\n# Compute pairwise differences between levels\ndiff_3_vs_2 = coef_3 - coef_2\ndiff_2_vs_1 = coef_2 - coef_1\n\nprint(f\"3:1 vs 2:1 difference (from regression): {diff_3_vs_2:.4f}\")\nprint(f\"2:1 vs 1:1 difference (from regression): {diff_2_vs_1:.4f}\")\n\n3:1 vs 2:1 difference (from regression): 0.0019\n2:1 vs 1:1 difference (from regression): 0.0363\n\n\n\nmfx = probit_model2.get_margeff()\nprint(mfx.summary())\n\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio[T.1]     0.0031      0.002      1.724      0.085      -0.000       0.007\nratio[T.2]     0.0049      0.002      2.786      0.005       0.001       0.008\nratio[T.3]     0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n\nmarginal_effects = mfx.margeff\nprint(\"Marginal effects by ratio level:\", marginal_effects)\n\n# Compare 2:1 to 1:1, 3:1 to 2:1\ndiff_2_vs_1 = marginal_effects[1] - marginal_effects[0]\ndiff_3_vs_2 = marginal_effects[2] - marginal_effects[1]\n\nprint(f\"Estimated increase from 1:1 to 2:1: {diff_2_vs_1:.4f}\")\nprint(f\"Estimated increase from 2:1 to 3:1: {diff_3_vs_2:.4f}\")\n\nMarginal effects by ratio level: [0.0030624  0.0048688  0.00496109]\nEstimated increase from 1:1 to 2:1: 0.0018\nEstimated increase from 2:1 to 3:1: 0.0001\n\n\n\ncontrol = df.loc[df.treatment == 0, 'amount'].dropna()\ntreatment = df.loc[df.treatment == 1, 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test Results:\n      \nControl mean: ${control.mean():,.2f}\nTreatment mean: ${treatment.mean():,.2f}\n      \nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null\nhypothesis that the mean donation amount of the two samples are equal.''')\n\n\nT-test Results:\n      \nControl mean: $0.81\nTreatment mean: $0.97\n      \nt-statistic: -1.8605020225753781\np-value: 0.06282038947470686\n\nAt the 95% confidence level, we fail to reject the null\nhypothesis that the mean donation amount of the two samples are equal.\n\n\n\ncontrol = df.loc[(df.treatment == 0) & (df.gave == 1), 'amount'].dropna()\ntreatment = df.loc[(df.treatment == 1) & (df.gave == 1), 'amount'].dropna()\n\nt_stat, pval = ttest_ind(control, treatment)\n\nprint(f'''\nT-test Results:\n      \nControl mean: ${control.mean():,.2f}\nTreatment mean: ${treatment.mean():,.2f}\n\nt-statistic: {t_stat}\np-value: {pval}\n\nAt the 95% confidence level, we {pval &lt; 0.05 and \"reject\" or \"fail to reject\"} the null\nhypothesis that the donation amount of the two samples are equal.''')\n\n\nT-test Results:\n      \nControl mean: $45.54\nTreatment mean: $43.87\n\nt-statistic: 0.5808388615237938\np-value: 0.5614758782284279\n\nAt the 95% confidence level, we fail to reject the null\nhypothesis that the donation amount of the two samples are equal.\n\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\naxes[0].set_ylabel(\"Frequency\")\n\nfor val in [0, 1]:\n    subset = df.loc[(df.gave == 1) & (df.treatment == val)].copy()\n    axes[val].hist(subset['amount'], bins=10)\n    axes[val].axhline(y=subset['amount'].mean(), color='r', linestyle='--', label=f'Mean: ${subset[\"amount\"].mean():,.2f}')\n    axes[val].legend()\n    axes[val].set_title(f'Amount Donated for {\"Treatment\" if val == 1 else \"Control\"} Group')\n    axes[val].set_xlabel(\"Dollars Donated\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nctr_p = 0.018\ntrt_p = 0.022\n\nnp.random.seed(12)\n\nsim_ctr = np.random.binomial(n=1, p=ctr_p, size=10_000)\nsim_trt = np.random.binomial(n=1, p=trt_p, size=10_000)\n\nsim_diff = sim_trt - sim_ctr\nsim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n\nprint(sim_diff.mean())\nprint(sim_diff_mean)\n\n0.005\n0.005000000000000001\n\n\n\ncumulative_avg = np.cumsum(sim_diff) / np.arange(1, len(sim_diff) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg)\nplt.axhline(y=trt_p - ctr_p, color='red', linestyle='--', label=f'True Effect ({trt_p-ctr_p:.3f})')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference (Treatment - Control)')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(2, 2, figsize=(8, 8), sharey=True, sharex=True)\naxes = axes.flatten()\naxes[0].set_ylabel(\"Frequency\")\naxes[2].set_ylabel(\"Frequency\")\naxes[2].set_xlabel(\"Difference in Response Rate\")\naxes[3].set_xlabel(\"Difference in Response Rate\")\n\nfor ax, size in enumerate([50, 200, 500, 1000]):\n    samples = []\n    for i in range(1000):\n        sim_ctr = np.random.binomial(n=1, p=ctr_p, size=size)\n        sim_trt = np.random.binomial(n=1, p=trt_p, size=size)\n\n        sim_diff_mean = sim_trt.mean() - sim_ctr.mean()\n        samples.append(sim_diff_mean)\n    \n    axes[ax].hist(samples, bins=np.linspace(-0.02, 0.03, 11))\n    axes[ax].axvline(x=trt_p - ctr_p, color='red', linestyle='--', label='True Effect (0.004)')\n    axes[ax].legend()\n    axes[ax].set_title(f'Average Difference from {size} Draws')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "code/old_code.html",
    "href": "code/old_code.html",
    "title": "Wesley Covey",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  }
]